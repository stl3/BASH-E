{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "118UKH5bWCGa"
      },
      "source": [
        "<center><img src=\"https://raw.githubusercontent.com/trekkie1701c/BASH-E/522540b5398b0ca98ea44ce738534821ec7c6890/backend/RobotCreation.jpg\" width=\"120\">\n",
        "</center>\n",
        "\n",
        "### <center>Use this notebook to run BASH-E</center>\n",
        "### <center> [BASH-E Repository](https://github.com/trekkie1701c/BASH-E) </center>\n",
        "\n",
        "#####<center>This notebook is based on the amazing [DALL·E Mini](https://github.com/borisdayma/dalle-mini) by [Boris Dayma](https://github.com/borisdayma) et al, and [DALL-E Playground](https://github.com/saharmor/dalle-playground)</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS8LbaonYm3a"
      },
      "source": [
        "## Collapse this and hit the start arrow to run everything.  Be sure to select a text prompt and number of images first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKmwZUHcl1bK"
      },
      "outputs": [],
      "source": [
        "#@title Select a model, text prompt, and number of images to generate - remember to execute cell after selecting!\n",
        "\n",
        "dalle_model = 'Mega_full' #@param [\"Mini\", \"Mega\", \"Mega_full\"]\n",
        "prompt = \"The Quick Brown Fox Jumps over the lazy dog\" #@param {type:\"string\"}\n",
        "num =  1 #@param {type:\"integer\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14b_iI4GWsUx"
      },
      "outputs": [],
      "source": [
        "#@title Mount your Google Drive account to save images\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyO_o-lTQn2A"
      },
      "outputs": [],
      "source": [
        "#@title Clone the Repo to your drive, install updates, and requirements.  Then change to the image save directory\n",
        "%cd /content/drive/MyDrive/\n",
        "!git clone https://github.com/trekkie1701c/BASH-E.git\n",
        "%cd BASH-E\n",
        "!git pull origin main\n",
        "!pip install -r backend/requirements.txt\n",
        "%cd /content/drive/MyDrive/images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVd-uID3e4lL"
      },
      "outputs": [],
      "source": [
        "#@title Install libraries to check for available memory.  This is useful to determine if you're hitting colab limits\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrRYWN7qTioY"
      },
      "outputs": [],
      "source": [
        "#@title Main Application execution\n",
        "print(f\"Selected DALL-E Model - [{dalle_model}]\")\n",
        "!python ../BASH-E/backend/BASH-E.py --model_version $dalle_model --prompt \"$prompt\" --num $num"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "BASH-E",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
